{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Cleaning belongs_to link csv\n",
    "\n",
    "# import ast\n",
    "\n",
    "# # taking dictionary out of string type\n",
    "# belongs_to_link['collection_id'] = belongs_to_link['collection_id'].apply(lambda x: ast.literal_eval(x)['id'])\n",
    "    \n",
    "# belongs_to_link.to_csv('final_belongs_to_clean2.csv')\n",
    "\n",
    "# Static Properties (do not change with input): popularity, ROI, weighted rating\n",
    "\n",
    "# Dynamic Properties (change according to input): belongs_to, genres, original_language, production_companies, \n",
    "# runtime (within 30 min radius + 1 point), release year (within 5 year radius + 1 point), cast, director\n",
    "\n",
    "# Loading in dataframes and storing as variables\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "from py2neo import Graph\n",
    "\n",
    "metadata = pd.read_csv('final_clean_metadata.csv')\n",
    "belongs_to = pd.read_csv('final_belongs_to_clean2.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# different approaches in 2 functions because one is comparing movies and one is comparing users so it doesn't\n",
    "# really make sense to combine \n",
    "# used small_ratings.csv so some movies are not included e.g. toystory \n",
    "\n",
    "# scores are between 0 and 1, 1 being the same \n",
    "# returns panda series\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_movie_rating_recommendations(title, df):\n",
    "    movieId = df.loc[df['title'] == title, 'id']\n",
    "\n",
    "    movies = metadata['id'].tolist()\n",
    "    rating = ratings[ratings['movieId'].isin(movies)]\n",
    "    df = rating.pivot_table(index=['userId'], columns=['movieId'], values='rating')\n",
    "    df = df.dropna(thresh=20, axis=1).fillna(0)\n",
    "\n",
    "    cosine_sim = cosine_similarity(df.T)\n",
    "\n",
    "    similarity_df = pd.DataFrame(cosine_sim, index=df.columns,columns=df.columns)\n",
    "\n",
    "    return similarity_df[movieId]\n",
    "\n",
    "get_movie_rating_recommendations('Toy Story', metadata)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_recommendations(title, df):\n",
    "    \n",
    "    count = CountVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "    count_matrix = count.fit_transform(df['text'])\n",
    "\n",
    "    cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "    df = df.reset_index()\n",
    "    titles = df['title']\n",
    "    indices = pd.Series(df.index, index=df['title'])\n",
    "    \n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sim_scores\n",
    "\n",
    "get_recommendations('Toy Story', metadata)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def normalize_static_values(df_column):\n",
    "    \n",
    "    x = df_column.values\n",
    "    x = x.reshape(-1,1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    df_column = pd.DataFrame(x_scaled)\n",
    "    \n",
    "    return df_column\n",
    "\n",
    "def movietitle_to_movieid(movie_title, df):\n",
    "    row_index = df['title'].index[df['title'] == movie_title][0]\n",
    "    return df['id'][row_index]\n",
    "\n",
    "\n",
    "\n",
    "# combined movie recommendation engine\n",
    "\n",
    "def recommend_hybrid(movie_title, df1, belongs_to_df):    \n",
    "    \n",
    "    if movie_title not in list(df1['title']):\n",
    "        print('Invalid movie title, try again!')    \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # converting supplied movie_title to movie_id\n",
    "        movie_id = movietitle_to_movieid(movie_title, df1)\n",
    "    \n",
    "        # creates a copy of the dataframe to manipulate\n",
    "        df = df1.copy()\n",
    "        \n",
    "        #grabs index of movie's data row\n",
    "        row_index = df['id'].index[df['id'] == movie_id][0]\n",
    "        \n",
    "        \n",
    "        movie1_points = get_recommendations(movie_title, df)\n",
    "        df['movie1_points'] = ''\n",
    "        \n",
    "        for tup in movie1_points:\n",
    "            index = tup[0]\n",
    "            value = tup[1]\n",
    "            \n",
    "            if index != row_index:\n",
    "                df['movie1_points'][index] = value\n",
    "                \n",
    "            else:\n",
    "                df['movie1_points'][index] = -10\n",
    "                \n",
    "        \n",
    "        movie2_points = get_movie_rating_recommendations(movie_title, df)\n",
    "        df['movie2_points'] = \"\"\n",
    "        \n",
    "        movie2_indexing = movie2_points[movie_id].index.tolist()\n",
    "        movie2_value = movie2_points[movie_id].tolist()\n",
    "        movie2_count = 0\n",
    "        for ind in movie2_indexing:\n",
    "            df_index = df['id'].index[df['id'] == ind][0]\n",
    "            \n",
    "            if ind != movie_id:\n",
    "                df['movie2_points'][df_index] = movie2_value[movie2_count]\n",
    "                \n",
    "            else:\n",
    "                df['movie2_points'][df_index] = -10\n",
    "            \n",
    "            movie2_count += 1\n",
    "            \n",
    "        df['movie2_points'].replace(\"\", 0, inplace = True)\n",
    "                        \n",
    "        # Normalizing static value columns in new dataframe\n",
    "        df['popularity'] = normalize_static_values(df['popularity'])\n",
    "        df['ROI'] = normalize_static_values(df['ROI'])\n",
    "        df['weighted_rating'] = normalize_static_values(df['weighted_rating'])\n",
    "        \n",
    "        # Creating new column to aggregate normalized static values\n",
    "        df['total_static_value'] = df['popularity'] + df['ROI'] + df['weighted_rating']\n",
    "\n",
    "        # creates dictionary of metadata specific to supplied movie_id\n",
    "        metadata = {}\n",
    "        metadata['belongs_to_collection'] = df.iloc[row_index]['belongs_to_collection']\n",
    "        metadata['genres'] = ast.literal_eval(df.iloc[row_index]['genres'])\n",
    "        metadata['production_companies'] = ast.literal_eval(df.iloc[row_index]['production_companies'])\n",
    "        metadata['runtime'] = int(df.iloc[row_index]['runtime'])\n",
    "        metadata['title'] = df.iloc[row_index]['title']\n",
    "        metadata['release_year'] = int(df.iloc[row_index]['release_year'])\n",
    "        metadata['cast'] = ast.literal_eval(df.iloc[row_index]['cast'])\n",
    "        metadata['director'] = df.iloc[row_index]['director']\n",
    "\n",
    "        # creating column of point counters starting at zero; point(s) added everytime dynamic property matches \n",
    "        df['dp_counter'] = pd.Series([0 for x in range(len(df.index))], index = df.index)\n",
    "\n",
    "        # retrieving related movies if it belongs to a collection (sequels, etc.)\n",
    "        if metadata['belongs_to_collection'] == 1: \n",
    "            belong_row_index = belongs_to_df['id'].index[belongs_to_df['id'] == movie_id][0]\n",
    "            collection_id = belongs_to_df['collection_id'][belong_row_index]\n",
    "\n",
    "            belong_counter = 0       # to keep track of index in belong_df\n",
    "            related_movie_l = []\n",
    "\n",
    "            for val in belongs_to_df['collection_id']: # to get index of related movie in belong_df\n",
    "                if val == collection_id:\n",
    "                    related_movie_l.append(belong_counter)\n",
    "                belong_counter += 1\n",
    "\n",
    "            # adding five points to related movie's dp counter (movie collection is weighted the most)\n",
    "            for ind in related_movie_l:\n",
    "                related_movie = belongs_to_df['id'][ind]\n",
    "                if related_movie != movie_id:\n",
    "                    related_movie_row_index = df['id'].index[df['id'] == related_movie][0]\n",
    "                    df['dp_counter'][related_movie_row_index] += 5 \n",
    "\n",
    "        # adding point(s) for genre (1 point for every genre that matches, if any)\n",
    "        genre_counter = 0 # to keep track of index\n",
    "        for genre in df['genres']:\n",
    "            genre = ast.literal_eval(genre)\n",
    "            for element in genre:\n",
    "                if genre_counter != row_index:\n",
    "                    if element in metadata['genres']:\n",
    "                        df['dp_counter'][genre_counter] += 1\n",
    "            genre_counter += 1\n",
    "\n",
    "        # adding point(s) for production company (1 point for every company that matches, if any)\n",
    "        production_counter = 0\n",
    "        for production_co in df['production_companies']:\n",
    "            production_co = ast.literal_eval(production_co)\n",
    "            for element in production_co:\n",
    "                if production_counter != row_index:\n",
    "                    if element in metadata['production_companies']:\n",
    "                        df['dp_counter'][production_counter] += 1\n",
    "            production_counter += 1\n",
    "\n",
    "        # adding point(s) for cast members (1 point for every cast member that matches, if any)\n",
    "        cast_counter = 0\n",
    "        for cast in df['cast']:\n",
    "            cast = ast.literal_eval(cast)\n",
    "            for element in cast:\n",
    "                if cast_counter != row_index:\n",
    "                    if element in metadata['cast']:\n",
    "                        df['dp_counter'][cast_counter] += 1\n",
    "            cast_counter += 1\n",
    "\n",
    "        # adding 3 points if director matches\n",
    "        director_counter = 0\n",
    "        for director in df['director']:\n",
    "            if director_counter != row_index:\n",
    "                if director == metadata['director']:\n",
    "                    df['dp_counter'][director_counter] += 3\n",
    "            director_counter += 1\n",
    "\n",
    "        # add 1 point if movie within 15 min runtime radius\n",
    "        runtime_counter = 0\n",
    "        for runtime in df['runtime']:\n",
    "            runtime = int(runtime)\n",
    "            if runtime_counter != row_index:\n",
    "                if runtime in list(range(metadata['runtime'] - 15, metadata['runtime'] + 15)):\n",
    "                    df['dp_counter'][runtime_counter] += 1\n",
    "            runtime_counter += 1\n",
    "\n",
    "        # add 1 point if movie within 3 year release_year radius\n",
    "        release_year_counter = 0\n",
    "        for release_year in df['release_year']:\n",
    "            release_year = int(release_year)\n",
    "            if release_year_counter != row_index:\n",
    "                if release_year in list(range(metadata['release_year'] - 3, metadata['release_year'] + 3)):\n",
    "                    df['dp_counter'][release_year_counter] += 1\n",
    "            release_year_counter += 1     \n",
    "        \n",
    "        df['total_point_value'] = df['total_static_value'] + df['dp_counter']\n",
    "        \n",
    "        # Normalizing static value columns in new dataframe\n",
    "        df['total_point_value'] = normalize_static_values(df['total_point_value'])\n",
    "        \n",
    "        df['total_content_point_value'] = df['total_point_value'] + df['movie1_points']\n",
    "        \n",
    "#         df['total_content_point_value'] = normalize_static_values(df['total_content_point_value'])\n",
    "        \n",
    "        df['final_point_value'] = df['total_content_point_value'] + df['movie2_points']\n",
    "        \n",
    "        df.sort_values(['final_point_value'], ascending=False, inplace=True)\n",
    "        return df['title'][:10]\n",
    "#         df.to_csv('testest12321.csv')\n",
    "\n",
    "\n",
    "\n",
    "# approach which takes in a user and gives the movie recommendations using Neo4j\n",
    "pd.set_option('expand_frame_repr', True)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option('max_colwidth',100)\n",
    "\n",
    "# graph = Graph(\"http://neo4j:123@localhost:7474/db/data\")\n",
    "# graph.run(\"load CSV with headers from 'file:///ratingsview.csv' as row merge(m:Movie {movieid:row.movieId, title:row.title}) merge(u:User {userid:row.userId}) merge(u)-[:Rated {rating:row.rating}]-> (m) Return m, u\")\n",
    "\n",
    "\n",
    "# def user_recommendation(userid):\n",
    "\n",
    "#     knnquery = 'MATCH (u1:User {userid: $userid })-[r:Rated]->(m:Movie) WITH u1, avg(r.rating) AS u1_avg MATCH (u1)-[r1:Rated]->(m:Movie)<-[r2:Rated]-(u2) WITH u1, u1_avg, u2, COLLECT({r1: r1, r2: r2}) AS ratings WHERE size(ratings) > 10 MATCH (u2)-[r:Rated]->(m:Movie) WITH u1, u1_avg, u2, avg(r.rating) AS u2_avg, ratings UNWIND ratings AS r WITH sum( (r.r1.rating-u1_avg) * (r.r2.rating-u2_avg) ) AS nom, sqrt( sum( (r.r1.rating - u1_avg)^2) * sum( (r.r2.rating - u2_avg) ^2)) AS denom, u1, u2 WHERE denom <> 0 WITH u1, u2, nom/denom AS pearson ORDER BY pearson DESC LIMIT 10 MATCH (u2)-[r:Rated]->(m:Movie) WHERE NOT EXISTS( (u1)-[:Rated]->(m) ) RETURN m.title, SUM( pearson * r.rating) AS score ORDER BY score DESC LIMIT 25'\n",
    "    \n",
    "#     result = graph.run(knnquery, userid=userid)\n",
    "    \n",
    "#     recommendation = []\n",
    "#     score = []\n",
    "    \n",
    "#     for node in result:\n",
    "#         recommendation.append(node[0])\n",
    "#         score.append(node[1])\n",
    "    \n",
    "#     recommendations = pd.DataFrame(columns = [\"Movie\", \"Score\"])\n",
    "    \n",
    "#     for i in range(0, len(recommendation)):\n",
    "#         recommendations = recommendations.append({\"Movie\":recommendation[i], \n",
    "#                                                   \"Score\":score[i]}, ignore_index=True)\n",
    "    \n",
    "#     print(recommendations)\n",
    "    \n",
    "# user_recommendation(168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1112           Toy Story 2\n",
       "833           A Bug's Life\n",
       "2490                  Cars\n",
       "3059           Toy Story 3\n",
       "3218                Cars 2\n",
       "1624        Monsters, Inc.\n",
       "1479                 Shrek\n",
       "230              Space Jam\n",
       "1695               Ice Age\n",
       "2654    The Simpsons Movie\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_hybrid('Toy Story', metadata, belongs_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
